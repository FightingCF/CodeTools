{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inverse depth sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.        ,   8.33333333,   4.34782609,   2.94117647,\n",
       "         2.22222222,   1.78571429,   1.49253731,   1.28205128,\n",
       "         1.12359551,   1.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def inv_depths(start_depth, end_depth, num_depths):\n",
    "    \"\"\"Sample reversed, sorted inverse depths between a near and far plane.\n",
    "\n",
    "    Args:\n",
    "      start_depth: The first depth (i.e. near plane distance).\n",
    "      end_depth: The last depth (i.e. far plane distance).\n",
    "      num_depths: The total number of depths to create. start_depth and\n",
    "          end_depth are always included and other depths are sampled\n",
    "          between them uniformly according to inverse depth.\n",
    "    Returns:\n",
    "      The depths sorted in descending order (so furthest first). This order is\n",
    "      useful for back to front compositing.\n",
    "    \"\"\"\n",
    "    return 1.0 / np.linspace(1.0 / start_depth, 1.0 / end_depth, num_depths)[::-1]\n",
    "inv_depths(1, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct a meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def meshgrid_torch(batch, height, width, device, permute):\n",
    "    xs = torch.linspace(0.0, width - 1, width)\n",
    "    ys = torch.linspace(0.0, height - 1, height)\n",
    "    ys, xs = torch.meshgrid(ys, xs, indexing='ij')\n",
    "    ones = torch.ones_like(xs)\n",
    "    coords = torch.stack([xs, ys, ones], axis=0)\n",
    "\n",
    "    grid = torch.unsqueeze(coords, 0).repeat(batch, 1, 1, 1).to(device=device)\n",
    "    if permute:\n",
    "        grid = grid.permute(0, 2, 3, 1)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform coordinates from pixel to camera space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix2cam_torch(depth, pixel_coords, intrinsics, is_homogeneous=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    depth: [batch, height, width]\n",
    "    pixel_coords: homogeneous pixel coordinates [batch, 3, height, width] (generated from above function)\n",
    "    intrinsics: camera intrinsics [batch, 3, 3]\n",
    "    is_homogeneous: return in homogeneous coordinates\n",
    "    Returns:\n",
    "    Coords in the camera frame [batch, 3 (4 if homogeneous), height, width]\n",
    "    \"\"\"\n",
    "    batch, height, width = depth.shape\n",
    "    depth = torch.reshape(depth, [batch, 1, -1])\n",
    "    pixel_coords = torch.reshape(pixel_coords, [batch, 3, -1])\n",
    "    cam_coords = torch.matmul(torch.inverse(intrinsics), pixel_coords) * depth\n",
    "\n",
    "    if is_homogeneous:\n",
    "        ones = torch.ones([batch, 1, height * width], device=pixel_coords.device)\n",
    "    cam_coords = torch.cat([cam_coords, ones], axis=1)\n",
    "    cam_coords = torch.reshape(cam_coords, [batch, -1, height, width])\n",
    "    return cam_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform coordinates from camera to pixel space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam2pixel_torch(cam_coords, proj):\n",
    "    \"\"\"Transforms coordinates in a camera frame to the pixel frame.\n",
    "\n",
    "    Args:\n",
    "    cam_coords: [batch, 4, height, width]\n",
    "    proj: [batch, 4, 4]\n",
    "    Returns:\n",
    "    Pixel coordinates projected from the camera frame [batch, height, width, 2]\n",
    "    \"\"\"\n",
    "    batch, _, height, width = cam_coords.shape\n",
    "    cam_coords = torch.reshape(cam_coords, [batch, 4, -1])\n",
    "    unnormalized_pixel_coords = torch.matmul(proj, cam_coords)\n",
    "    xy_u = unnormalized_pixel_coords[:, 0:2, :]\n",
    "    z_u = unnormalized_pixel_coords[:, 2:3, :]\n",
    "\n",
    "    pixel_coords = xy_u / (z_u + 1e-10)\n",
    "    pixel_coords = torch.reshape(pixel_coords, [batch, 2, height, width])\n",
    "    return pixel_coords.permute([0, 2, 3, 1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6c8cccf23fc189a51b8b2ae4ca3b98de763e12cce4f9033fe8d82721c91cecc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
